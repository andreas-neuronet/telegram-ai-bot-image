from gradio_client import Client
import os
from dotenv import load_dotenv
from PIL import Image
import requests
import logging

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
logging.basicConfig(filename='app.log', level=logging.INFO, 
                    format='%(asctime)s - %(levelname)s - %(message)s')

# === –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∞ –∏–∑ .env ===
load_dotenv()

HF_TOKEN = os.getenv("HF_TOKEN")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHANNEL_ID = os.getenv("TELEGRAM_CHANNEL_ID")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
if not HF_TOKEN:
    raise ValueError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω HF_TOKEN –≤ .env —Ñ–∞–π–ª–µ.")
if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHANNEL_ID:
    raise ValueError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã TELEGRAM_BOT_TOKEN –∏–ª–∏ TELEGRAM_CHANNEL_ID –≤ .env —Ñ–∞–π–ª–µ.")

print(f"TELEGRAM_BOT_TOKEN: {TELEGRAM_BOT_TOKEN[:5]}... (—Å–∫—Ä—ã—Ç)")
print(f"TELEGRAM_CHANNEL_ID: {TELEGRAM_CHANNEL_ID}")

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
MODEL_FILE = "MODEL.txt"
INPUT_FILENAME = "input.txt"
OUTPUT_DIR = "image"

# === –†–µ–∑–µ—Ä–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ ===
BACKUP_MODELS = [
    "black-forest-labs/FLUX.1-schnell",
    "stabilityai/stable-diffusion-xl-base-1.0",
    "runwayml/stable-diffusion-v1-5"
]

def get_working_model():
    if os.path.exists(MODEL_FILE):
        try:
            with open(MODEL_FILE, "r", encoding="utf-8") as f:
                models = [line.strip() for line in f if line.strip()]
                for model in models:
                    try:
                        print(f"üîÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏: {model}")
                        Client(model, hf_token=HF_TOKEN)
                        return model
                    except Exception as e:
                        print(f"‚ùå –ú–æ–¥–µ–ª—å {model} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
                        continue
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–µ–π: {e}")

    print("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É—é —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏...")
    for model in BACKUP_MODELS:
        try:
            Client(model, hf_token=HF_TOKEN)
            return model
        except Exception as e:
            print(f"‚ùå –†–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å {model} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
            continue

    raise ValueError("‚ùå –ù–∏ –æ–¥–Ω–∞ –∏–∑ –º–æ–¥–µ–ª–µ–π –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞!")

# === –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å ===
MODEL_NAME = get_working_model()
print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é –º–æ–¥–µ–ª—å: {MODEL_NAME}")
client = Client(MODEL_NAME, hf_token=HF_TOKEN)
os.makedirs(OUTPUT_DIR, exist_ok=True)

try:
    with open(INPUT_FILENAME, "r", encoding="utf-8") as f:
        prompts = [line.strip() for line in f if line.strip()]
except FileNotFoundError:
    print(f"‚ùå –§–∞–π–ª {INPUT_FILENAME} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    exit()

def send_to_telegram(image_path, caption=""):
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
    try:
        with open(image_path, "rb") as photo:
            files = {"photo": photo}
            data = {
                "chat_id": TELEGRAM_CHANNEL_ID,
                "caption": caption[:200],  # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
                "parse_mode": "Markdown"
            }
            response = requests.post(url, data=data, files=files)
            
            if response.status_code == 200:
                print("‚úÖ –£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram!")
                logging.info(f"Sent to Telegram: {image_path}")
                return True
            else:
                error_text = response.text
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ Telegram: –∫–æ–¥ {response.status_code}")
                print("–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞:", error_text)
                logging.error(f"Telegram error: {error_text}")
                return False
    except Exception as e:
        print(f"‚ö†Ô∏è –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ Telegram: {e}")
        logging.exception("Telegram send error")
        return False

for idx, prompt in enumerate(prompts):
    print(f"\nüîÑ [{idx + 1}/{len(prompts)}] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è: ¬´{prompt}¬ª")
    try:
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è FLUX.1-schnell
        if "FLUX.1-schnell" in MODEL_NAME:
            result = client.predict(
                prompt=prompt,
                api_name="/infer"
            )
        else:  # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π
            result = client.predict(
                prompt=prompt,
                seed=0,
                width=1024,
                height=1024,
                guidance_scale=3.5,
                num_inference_steps=28,
                api_name="/infer"
            )

        temp_image_path = result[0]
        safe_prompt = "".join(c for c in prompt[:30] if c.isalnum() or c in " _-")
        output_path = os.path.join(OUTPUT_DIR, f"{idx + 1}_{safe_prompt}.png")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
        with Image.open(temp_image_path) as img:
            img.save(output_path, "PNG", quality=100)
        print(f"üñºÔ∏è –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫ PNG: {output_path}")
        logging.info(f"Image saved: {output_path}")

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram
        if os.path.exists(output_path):
            print(f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram: {output_path}")
            success = send_to_telegram(output_path, caption=f"üñºÔ∏è {prompt}")
            if success:
                print("‚úÖ –£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram")
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ Telegram")
        else:
            print(f"‚ùå –§–∞–π–ª {output_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        logging.exception(f"Error processing prompt '{prompt}': {e}")

print("\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")